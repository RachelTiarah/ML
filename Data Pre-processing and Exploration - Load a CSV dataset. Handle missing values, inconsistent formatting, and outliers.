import pandas as pd
import numpy as np
import requests
from io import StringIO
from scipy import stats

# Step 1: Load the CSV data from the URL
url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'
columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']
response = requests.get(url)
csv_data = StringIO(response.text)

# Step 2: Create DataFrame
df = pd.read_csv(csv_data, header=None, names=columns)

# Step 3: Initial Information
print("Before Data Cleaning:")
print(df.info())
print(df.head())

# Step 4: Handle missing values
df_imputed = df.copy()

# Numeric columns – fill missing with mean
numeric_cols = df_imputed.select_dtypes(include=np.number).columns
df_imputed[numeric_cols] = df_imputed[numeric_cols].fillna(df_imputed[numeric_cols].mean())

# Categorical columns – fill missing with mode
categorical_cols = df_imputed.select_dtypes(include='object').columns
for col in categorical_cols:
    df_imputed[col].fillna(df_imputed[col].mode()[0], inplace=True)

# Step 5: Fix column formatting (strip spaces, lowercase)
df_imputed.columns = df_imputed.columns.str.strip().str.lower().str.replace(' ', '_')

# Step 6: Remove outliers using Z-score
z_scores = np.abs(stats.zscore(df_imputed.select_dtypes(include=np.number)))
outliers = (z_scores > 3)
df_cleaned = df_imputed[~np.any(outliers, axis=1)]

# Step 7: Show cleaned data
print("\nAfter Data Cleaning:")
print(df_cleaned.info())
print(df_cleaned.head())

# Step 8: Summary Statistics
print("\nSummary Statistics Before Cleaning:")
print(df.describe())

print("\nSummary Statistics After Cleaning:")
print(df_cleaned.describe())
